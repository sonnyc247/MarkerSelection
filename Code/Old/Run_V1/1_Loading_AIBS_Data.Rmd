---
title: "1: Loading AIBS Data"
author: "Anukrati, Sonny (Edited for use)"
output: html_document
---

This document details the code for loading AIBS human brain data. Some code came from Anukrati Nigam, edited for Sonny Chen's use/the write-up of this notebook.

This process will involve both R and bash code. Therefore, we first load the packages that will allow us to specify both in this rmarkdown document.

```{r, lang setup}

knitr::knit_engines
names(knitr::knit_engines$get())

```

We first dowload the data. Depending on access, we can dowload to either the lab folder or our personal folders.

```{r, downloading data}

human_url = 'https://transcriptomic-viewer-downloads.s3-us-west-2.amazonaws.com/human/transcriptome.zip'
#download_dir = '/external/rprshnas01/netdata_kcni/stlab/AIBS_scRNAseq_2019/human/' #no writing permission at the time of this code; the below is a work-around
download_dir = '/external/rprshnas01/kcni/ychen/References/AIBS_scRNAseq_2019/Human/'
download.file(human_url, destfile = paste0(download_dir, 'transcriptome.zip'), mode = 'wb')

```

To proceed, we will need to unzip the tome file. [This is not run in the current write-up of the notebook, because currently the file has already been unzipped, with the zipped file deleted]

```{bash, unzip data}

unzip "/external/rprshnas01/kcni/ychen/git/MarkerSelection/Data/transcriptome.zip" #change as appropriate, for your directory/path to data
rm "/external/rprshnas01/kcni/ychen/git/MarkerSelection/Data/transcriptome.zip"

```

After this, we can load the metadata and see what samples/cells our data contain. 

```{r, loading meta-data}

# download and attach needed packages
BiocManager::install("rhdf5") #needed to install scrattch.io
devtools::install_github("AllenInstitute/scrattch.io") #this is particularly important, it is the code from AIBS for working with their data

library(rhdf5)
library(scrattch.io) #package cheatsheet: https://docs.google.com/spreadsheets/d/1tJUgnfEXUv1IuzGAykDCTIUTsgzEWkT-jfl4UcEUl48/edit#gid=0
library(dplyr)

# reading the data into R

tome <- paste0(download_dir, 'transcrip.tome') #getting data filepath
tome_sample_name <- read_tome_sample_names(tome)  #getting sample names
tome_sample_meta <- read_tome_anno(tome) #getting sample annotation
tome_gene_name   <- read_tome_gene_names(tome) #getting gene names

### at this point, we can load all the samples/transcriptomic data (see "loading data" r chunk below), but if you know what cells you want to filter out, it is better to subset the sample names that you want so that you work with more manageable dataframes.

# for now, we can take a look at the metadata

identical(tome_sample_meta$cell_type_alias_label, tome_sample_meta$cluster_label) # to note, cell_type_alias_label and cluster_label are identical

tome_sample_meta[1:10,c("sample_name", "region_label", "class_label", "cell_type_alias_label")] #preview of a bit of data

```

Now we separate the clusters in the metadata into cell classes/subclasses/types to allow filtering, as the current version of metadata does not have a single column for each cell class/subclass/type.

```{r, cell clusters to cell class/subclass/type}

library(tidyr) #needed for the separate function
tome_sample_meta_filtered <- separate(data = tome_sample_meta, col = cell_type_alias_label, into = c("split_class", "split_layer", "split_subclass", "split_type"), sep = " ") #this splits the one column of cell identifiers into cell class, layer, subclass, and type

tome_sample_meta_filtered <- as.data.frame(tome_sample_meta_filtered) #fully convert metada df to df structure (else will get tibble warning message with the next line of code)
row.names(tome_sample_meta_filtered) <- tome_sample_meta_filtered$sample_name #sometimes the workflow requires rownames to be the sample names

tome_sample_meta_filtered[1:10,c(1,7:10)] #demonstration of the key identifiers that we want

```

Just as a sanity check, we will check all the cell factors/identifiers (for example, can do this with cell type, layer, region etc.)  and iterate over all split_subclass values to check whether there are multiple factor/identifier values (in the demo below, we are using split_class values) per split_subclass value. The demo below is important because different class-subclass combinations with the same subclass value but different class values may be indicative of different subclasses not captured by looking at subclass values alone.


```{r, sanity checks of metadata}

unique(tome_sample_meta_filtered$split_class) #checking out the class values
unique(tome_sample_meta_filtered$split_layer) #checking out the layer values
unique(tome_sample_meta_filtered$split_subclass) #checking out the subclass values
unique(tome_sample_meta_filtered$split_type) #checking out the type values

unique(tome_sample_meta_split$region_label) #sanity check for filtering

for (cell_identifier in unique(tome_sample_meta_filtered$split_subclass)) { #for every subclass, do:
  
  tmp_df <- tome_sample_meta_filtered[tome_sample_meta_filtered$split_subclass == cell_identifier,] #filter metadata df for the current subclass
  print(c(cell_identifier, unique(tmp_df$split_class))) #print the class values of the subsetted df
  
} #the below result may be different from your result due to later changes to the tome_sample_meta_filtered df (see further below)

```

As we can see above, each cell subclass only has one class value (except for outliers and donor-specific cell classes, which would show up with the first run of the code above). These are some of the cells we will filter out; along with other filters/selections of the cells that we want.

```{r, filtering meta-data to select cells}

tome_sample_meta_filtered <- tome_sample_meta_filtered[!(tome_sample_meta_filtered$class_label == "Exclude"),] # this is a merged-grouping of all Outlier and Donor split_class values, which we remove from the dataset

# see the effect of our filtering:

for (cell_identifier in unique(tome_sample_meta_filtered$split_subclass)) { #for every subclass, do:
  
  tmp_df <- tome_sample_meta_filtered[tome_sample_meta_filtered$split_subclass == cell_identifier,] #filter metadata df for the current subclass
  print(c(cell_identifier, unique(tmp_df$split_class))) #print the class values of the subsetted df
  
}

# for our purposes/demonstration, we remove all neurons not from the ACC

tome_sample_meta_filtered <-tome_sample_meta_filtered[!(tome_sample_meta_filtered$class_label!="Non-neuronal" & tome_sample_meta_filtered$region_label!="ACC"),]

# see the effect of our filtering:

for (cell_identifier in unique(tome_sample_meta_filtered$split_subclass)) { #for every subclass, do:
  
  tmp_df <- tome_sample_meta_filtered[tome_sample_meta_filtered$split_subclass == cell_identifier,] #filter metadata df for the current subclass
  print(c(cell_identifier, c(unique(tmp_df$class_label), unique(tmp_df$region_label)))) #print the class and region values of the subsetted df
  
}


```

As demonstrated above, the cell-subclasses are either neuronal from the ACC, or non-neuronal from any brain region in the full dataset.
Now we can load the actual count matrix data.

```{r, loading_data}

# if you skipped the filtering above, and just want to load in the full dataset from AIBS, then the following will work (adjust parameters as per your needs):

h5closeAll() #need to run, to prevent red wall of text when reading tome data
AIBS_Rawcount_InEx <- read_tome_sample_data(tome, tome_sample_name, regions = "both", units = "counts", transform = "none", format = "data.frame") #this generates the actual count dataframe in long form, we are getting Introns and Exons (regions = "both"), raw counts without any transformation, in a df format

# however, if we want our specific/filtered cells, then we need to first get a list of our sample names from our filtered dataframe:

query_sample_name_list <- tome_sample_meta_filtered$sample_name #extracting sample names from our filtered dataframe
head(tome_sample_name) #see what the sample name list from AIBS looks like structurally
head(query_sample_name_list) #see that our name list is structured the same way

# now we can extract our data from the AIBS tome: 

h5closeAll() #need to run, to prevent red wall of text when reading tome data (run this every time before every use of read_tome_sample_data)
AIBS_Rawcount_InEx <- read_tome_sample_data(tome, query_sample_name_list, regions = "both", units = "counts", transform = "none", format = "data.frame") #this generates the actual count dataframe in long form, we are getting Introns and Exons (regions = "both"), raw counts without any transformation, in a df format

```

The dataframe we get has gene names as the first column, which is generally not desired for most pipelines dealing with count matrices. Thus, we set the row names to the first column and remove the first column

```{r, genenames to rownames}

AIBS_Rawcount_InEx[1:10,1:5] #to illustrate where the gene name column is

row.names(AIBS_Rawcount_InEx) <- AIBS_Rawcount_InEx$gene_name #set row names
AIBS_Rawcount_InEx <- AIBS_Rawcount_InEx[,2:length(colnames(AIBS_Rawcount_InEx))] # remove gene name column from df

AIBS_Rawcount_InEx[1:10,1:5] #to illustrate where the gene name column is now

```

The count matrix is ready for work/conversion into another workable format.

This is the end of this script, for now. We will take this data into other scripts and convert into appropriate format as desired, ultimately leading to analysis.

Leftover/additional code from Anukrati (untested/unused by Sonny) for getting group averages

```{r, group_average_code}

#Access in data frame the cpm values per cluster
cluster_list <- unique(tome_sample_meta$cluster_label)

tome_avg_expr <- data.frame(expr_vals = numeric(), cluster = character())
for (cluster_name in cluster_list){
  tome_sample_name_temp <- tome_sample_meta %>% filter(cluster_label == cluster_name) %>% 
    pull(sample_name)
  tome_temp <- read_tome_sample_data(tome, tome_sample_name_temp, regions = "both",
                                            units = "cpm", transform = "log2", format = "matrix")
  tome_expr <- rowMeans(tome_temp)
  temp_df = data.frame(expr_vals = tome_expr, cluster = cluster_name)
  tome_avg_expr = rbind(tome_avg_expr, temp_df) 
  
}

#To get group averages per cluster
#Mean
tome_avg_expr %>% group_by(cluster) %>% summarise_all(list(avg= mean))
#Median
tome_avg_expr %>% group_by(cluster) %>% summarise_all(list(med= median))

```

